{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layer_dims):\n",
    "    parameters={}\n",
    "    L=len(layer_dims)\n",
    "    for i in range(1,L):\n",
    "        parameters['W'+str(i)]=np.random.randn(layer_dims[i],layer_dims[1-1])*0.01\n",
    "        parameters['b'+str(i)]=np.zeros((layer_dims[i],1))\n",
    "        #assert(parameters['W' + str(i)].shape == (layer_dims[i], layer_dims[i-1]))\n",
    "        #assert(parameters['b' + str(i)].shape == (layer_dims[i], 1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liner_forward(A,W,b):\n",
    "    Z=np.dot(W,A)+b\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A= 1/(1+np.exp(-Z))\n",
    "    cache= Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A= Z*(Z>0)\n",
    "    cache= Z\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    Z, linear_cache= linear_forward(A_prev, W, b)\n",
    "    if activation== \"sigmoid\":\n",
    "        A, activation_cache= sigmoid(Z)\n",
    "    elif activation== \"relu\":\n",
    "        A, activation_cache= relu(Z)\n",
    "    assert(A.shape== (W.shape[0], A_prev.shape[1]))\n",
    "    cache= (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches=[]\n",
    "    A=X\n",
    "    L=len(parameters)//2\n",
    "    for i in range(1,L):\n",
    "        A_prev= A\n",
    "        A, cache= linear_activation_forward(A_prev, parameters('W'+str(i)), parameters('b'+str(i)), activation=\"relu\")\n",
    "        caches.append(cache)\n",
    "    AL,cache= linear_activation_forward(A, parameters('W'+str(L)), parameters('b'+str(L)), activation=\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape==(1,X.shape[1]))\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m=Y.shape[1]\n",
    "    cost = -sum(sum(np.multiply(Y,np.log(AL))+np.multiply(1-Y,np.log(1-AL))))/m\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = np.dot(dZ,A_prev.T)/m  \n",
    "    db = np.sum(dZ, axis=1, keepdims=True )/m\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(Z):\n",
    "    f, g= sigmoid(Z)\n",
    "    return f*(1-f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(Z):\n",
    "    Z[Z<=0] = 0\n",
    "    Z[Z>0] = 1\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, activation_cache):\n",
    "    Z= activation_cache\n",
    "    return dA*sigmoid_derivative(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, activation_cache):\n",
    "    Z= activation_cache\n",
    "    return dA*relu_derivative(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    dAL =  -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))   \n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation= \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation= \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] =  parameters[\"W\" + str(l+1)] -learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] -learning_rate*grads[\"db\" + str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= 'titanic_train.csv'\n",
    "test_data=\"titanic_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass                                               Name  \\\n",
      "PassengerId                                                              \n",
      "1                 3                            Braund, Mr. Owen Harris   \n",
      "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "3                 3                             Heikkinen, Miss. Laina   \n",
      "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "5                 3                           Allen, Mr. William Henry   \n",
      "\n",
      "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
      "PassengerId                                                                \n",
      "1              male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
      "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
      "3            female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
      "4            female  35.0      1      0            113803  53.1000  C123   \n",
      "5              male  35.0      0      0            373450   8.0500   NaN   \n",
      "\n",
      "            Embarked  \n",
      "PassengerId           \n",
      "1                  S  \n",
      "2                  C  \n",
      "3                  S  \n",
      "4                  S  \n",
      "5                  S  \n"
     ]
    }
   ],
   "source": [
    "X= pd.read_csv(data, index_col='PassengerId')\n",
    "X_test=pd.read_csv(test_data, index_col=\"PassengerId\")\n",
    "Y= X.Survived\n",
    "X=X.drop(['Survived'], axis=1)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols with missing:  ['Age', 'Cabin', 'Embarked']\n",
      "object cols:  ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "no. of unique entries:  {'Name': 891, 'Sex': 2, 'Ticket': 681, 'Cabin': 147, 'Embarked': 3}\n",
      "low_cardinality_cols:  ['Sex', 'Embarked']\n",
      "high_cardinality_cols:  ['Ticket', 'Name', 'Cabin']\n",
      "numerical_cols ['SibSp', 'Pclass', 'Parch', 'Age', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()]\n",
    "print(\"cols with missing: \",cols_with_missing)\n",
    "object_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "print(\"object cols: \",object_cols)\n",
    "object_nunique = list(map(lambda col: X[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "print(\"no. of unique entries: \", d)\n",
    "low_cardinality_cols = [col for col in object_cols if X[col].nunique() < 10]\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "print(\"low_cardinality_cols: \",low_cardinality_cols)\n",
    "print(\"high_cardinality_cols: \", high_cardinality_cols)\n",
    "numerical_cols= list(set(X.columns)-set(object_cols))\n",
    "print(\"numerical_cols\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X.drop(high_cardinality_cols, axis=1)\n",
    "X_test= X_test.drop(high_cardinality_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                           ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),\n",
    "                                                 ('cat', categorical_transformer, low_cardinality_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "PassengerId                                                      \n",
      "1                 3    male  22.0      1      0   7.2500        S\n",
      "2                 1  female  38.0      1      0  71.2833        C\n",
      "3                 3  female  26.0      0      0   7.9250        S\n",
      "4                 1  female  35.0      1      0  53.1000        S\n",
      "5                 3    male  35.0      0      0   8.0500        S\n",
      "...             ...     ...   ...    ...    ...      ...      ...\n",
      "887               2    male  27.0      0      0  13.0000        S\n",
      "888               1  female  19.0      0      0  30.0000        S\n",
      "889               3  female   NaN      1      2  23.4500        S\n",
      "890               1    male  26.0      0      0  30.0000        C\n",
      "891               3    male  32.0      0      0   7.7500        Q\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "                    0         1         2             3         4         5  \\\n",
      "PassengerId                                                                   \n",
      "1            0.432793  0.827377 -0.473674 -5.924806e-01 -0.502445 -0.737695   \n",
      "2            0.432793 -1.566107 -0.473674  6.387890e-01  0.786845  1.355574   \n",
      "3           -0.474545  0.827377 -0.473674 -2.846632e-01 -0.488854  1.355574   \n",
      "4            0.432793 -1.566107 -0.473674  4.079260e-01  0.420730  1.355574   \n",
      "5           -0.474545  0.827377 -0.473674  4.079260e-01 -0.486337 -0.737695   \n",
      "...               ...       ...       ...           ...       ...       ...   \n",
      "887         -0.474545 -0.369365 -0.473674 -2.077088e-01 -0.386671 -0.737695   \n",
      "888         -0.474545 -1.566107 -0.473674 -8.233437e-01 -0.044381  1.355574   \n",
      "889          0.432793  0.827377  2.008933  4.374348e-15 -0.176263  1.355574   \n",
      "890         -0.474545 -1.566107 -0.473674 -2.846632e-01 -0.044381 -0.737695   \n",
      "891         -0.474545  0.827377 -0.473674  1.770629e-01 -0.492378 -0.737695   \n",
      "\n",
      "                    6         7         8         9  \n",
      "PassengerId                                          \n",
      "1            0.737695 -0.482043 -0.307562  0.615838  \n",
      "2           -1.355574  2.074505 -0.307562 -1.623803  \n",
      "3           -1.355574 -0.482043 -0.307562  0.615838  \n",
      "4           -1.355574 -0.482043 -0.307562  0.615838  \n",
      "5            0.737695 -0.482043 -0.307562  0.615838  \n",
      "...               ...       ...       ...       ...  \n",
      "887          0.737695 -0.482043 -0.307562  0.615838  \n",
      "888         -1.355574 -0.482043 -0.307562  0.615838  \n",
      "889         -1.355574 -0.482043 -0.307562  0.615838  \n",
      "890          0.737695  2.074505 -0.307562 -1.623803  \n",
      "891          0.737695 -0.482043  3.251373 -1.623803  \n",
      "\n",
      "[891 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "X_transformed= preprocessor.fit_transform(X)\n",
    "X_transformed= pd.DataFrame(StandardScaler().fit_transform(X_transformed))\n",
    "X_transformed.index= X.index\n",
    "print(X)\n",
    "print(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
      "PassengerId                                                       \n",
      "892               3    male  34.5      0      0    7.8292        Q\n",
      "893               3  female  47.0      1      0    7.0000        S\n",
      "894               2    male  62.0      0      0    9.6875        Q\n",
      "895               3    male  27.0      0      0    8.6625        S\n",
      "896               3  female  22.0      1      1   12.2875        S\n",
      "...             ...     ...   ...    ...    ...       ...      ...\n",
      "1305              3    male   NaN      0      0    8.0500        S\n",
      "1306              1  female  39.0      0      0  108.9000        C\n",
      "1307              3    male  38.5      0      0    7.2500        S\n",
      "1308              3    male   NaN      0      0    8.0500        S\n",
      "1309              3    male   NaN      1      1   22.3583        C\n",
      "\n",
      "[418 rows x 7 columns]\n",
      "                    0         1         2             3         4         5  \\\n",
      "PassengerId                                                                   \n",
      "892         -0.499470  0.873482 -0.400248  3.349926e-01 -0.498407 -0.755929   \n",
      "893          0.616992  0.873482 -0.400248  1.325530e+00 -0.513274  1.322876   \n",
      "894         -0.499470 -0.315819 -0.400248  2.514175e+00 -0.465088 -0.755929   \n",
      "895         -0.499470  0.873482 -0.400248 -2.593299e-01 -0.483466 -0.755929   \n",
      "896          0.616992  0.873482  0.619896 -6.555448e-01 -0.418471  1.322876   \n",
      "...               ...       ...       ...           ...       ...       ...   \n",
      "1305        -0.499470  0.873482 -0.400248 -2.533749e-15 -0.494448 -0.755929   \n",
      "1306        -0.499470 -1.505120 -0.400248  6.915861e-01  1.313753  1.322876   \n",
      "1307        -0.499470  0.873482 -0.400248  6.519646e-01 -0.508792 -0.755929   \n",
      "1308        -0.499470  0.873482 -0.400248 -2.533749e-15 -0.494448 -0.755929   \n",
      "1309         0.616992  0.873482  0.619896 -2.533749e-15 -0.237906 -0.755929   \n",
      "\n",
      "                    6         7         8         9  \n",
      "PassengerId                                          \n",
      "892          0.755929 -0.568142  2.843757 -1.350676  \n",
      "893         -1.322876 -0.568142 -0.351647  0.740370  \n",
      "894          0.755929 -0.568142  2.843757 -1.350676  \n",
      "895          0.755929 -0.568142 -0.351647  0.740370  \n",
      "896         -1.322876 -0.568142 -0.351647  0.740370  \n",
      "...               ...       ...       ...       ...  \n",
      "1305         0.755929 -0.568142 -0.351647  0.740370  \n",
      "1306        -1.322876  1.760125 -0.351647 -1.350676  \n",
      "1307         0.755929 -0.568142 -0.351647  0.740370  \n",
      "1308         0.755929 -0.568142 -0.351647  0.740370  \n",
      "1309         0.755929  1.760125 -0.351647 -1.350676  \n",
      "\n",
      "[418 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test_trans= preprocessor.fit_transform(X_test)\n",
    "X_test_trans= pd.DataFrame(StandardScaler().fit_transform(X_test_trans))\n",
    "X_test_trans.index= X_test.index\n",
    "print(X_test)\n",
    "print(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val= train_test_split(X_transformed, Y, test_size=0.3, random_state= 1)\n",
    "X_train=X_train.T\n",
    "X_val= X_val.T\n",
    "train_indices=Y_train.index\n",
    "val_indices=Y_val.index\n",
    "Y_train= np.array([Y_train])\n",
    "Y_val= np.array([Y_val])\n",
    "X_test= X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS ###\n",
    "layers_dims = [10, 6, 4, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []                      \n",
    "    parameters = init_params(layers_dims)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b4e8371dc327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-1c878a1e3e5e>\u001b[0m in \u001b[0;36mL_layer_model\u001b[0;34m(X, Y, layers_dims, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_model_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_model_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-91724eaeaed9>\u001b[0m in \u001b[0;36mL_model_forward\u001b[0;34m(X, parameters)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mA_prev\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlinear_activation_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcaches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlinear_activation_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train, Y_train, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
